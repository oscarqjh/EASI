# üìä Benchmark Verification

Validation of EASI implementations against official reported scores.

## üü¢ Status Legend & Methodology

The status is based on the absolute difference $\lvert\Delta\rvert$.

| Symbol | Status | Criteria |
| :---: | :--- | :--- |
| ‚úÖ | **Strong Agreement** | $0.0\\% \\le \\lvert\\Delta\\rvert \\le 2.5\\%$ |
| ‚òëÔ∏è | **Acceptable Variance** | $2.5\\% < \\lvert\\Delta\\rvert \le 5.0\\%$ |
| ‚ùå | **Discrepancy** | $5.0\\% < \\lvert\\Delta\\rvert$ |

> **üìù Note on $\Delta$ Calculation:**
> * Formula: $\Delta = \text{EASI (Corresponding backend)} - \text{Target Score}$
> * **Target Source:** We prioritize the **Official Code** (local run of the official codebase) to strictly verify implementation correctness. If strict reproduction is not performed, we align with the **Paper Reported** score.
---

## üìë Index
*(Matches the order in [Supported Benchmarks](./Support_bench_models.md))*

1. [MindCube](#1-mindcube)
2. [ViewSpatial](#2-viewspatial)
3. [EmbSpatial-Bench](#3-embspatial-bench)
4. [MMSI-Bench (no circular)](#4-mmsi-bench-no-circular)
5. [VSI-Bench](#5-vsi-bench)
6. [VSI-Bench-Debiased](#6-vsi-bench-debiased)
7. [SITE-Bench](#7-site-bench)
8. [SPAR-Bench](#8-spar-bench)
9. [STARE-Bench](#9-stare-bench)
10. [Spatial-Visualization-Benchmark](#10-spatial-visualization-benchmark)
11. [OmniSpatial](#11-omnispatial)
12. [ERQA](#12-erqa)
13. [RefSpatial-Bench](#13-refspatial-bench)
14. [RoboSpatial-Home](#14-robospatial-home)
15. [SPBench](#15-spbench)
16. [MMSI-Video-Bench](#16-mmsi-video-bench)
17. [VSI-SUPER-Recall](#17-vsi-super-recall)
18. [VSI-SUPER-Count](#18-vsi-super-count)
19. [STI-Bench](#19-sti-bench)
20. [DSR-Bench](#20-dsr-bench)

---

## üî¨ Detailed Verification

### 1. MindCube
* **Metric:** Accuracy

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status | EASI (backend=lmms-eval) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | 
| Qwen2.5-VL-3B-Instruct | `MindCubeBench_tiny_raw_qa` | 37.81 | - | 37.88 | +0.07 | ‚úÖ | 34.08 | +3.73 | ‚òëÔ∏è
| Qwen2.5-VL-3B-Instruct | `MindCubeBench_raw_qa` | 33.21 | 36.08 | 35.65 | -0.43 | ‚úÖ | 34.97 | -1.11 | ‚úÖ
| Qwen2.5-VL-7B-Instruct | `MindCubeBench_raw_qa` | 29.26 | 31.12 | 31.48 | +0.36 | ‚úÖ | 30.60 | -0.52 | ‚úÖ


### 2. ViewSpatial
* **Metric:** Accuracy

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status | EASI (backend=lmms-eval) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct | `ViewSpatialBench` | 35.85 | - | 31.97 | -3.88 | ‚òëÔ∏è | 32.23 | -3.62 | ‚òëÔ∏è |
| Qwen2.5-VL-7B-Instruct | `ViewSpatialBench` | 36.85 | - | 36.85 | +0.00 | ‚úÖ | 36.43 | -0.42 | ‚úÖ |
| InternVL3-14B | `ViewSpatialBench` | 40.28 | - | 40.53 | +0.25 | ‚úÖ | 40.70 | +0.42 | ‚úÖ |


### 3. EmbSpatial-Bench
* **Metric:** Accuracy

| Model | Benchmark | Paper | Qwen3-VL-Report | EASI (backend=VLMEvalKit) | Œî | Status | EASI (backend=lmms-eval) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Qwen3-VL-4B-Instruct | `EmbSpatialBench` | - | 79.60 | 78.70 | -0.90 | ‚úÖ | 76.81 | -2.79 | ‚òëÔ∏è |
| Qwen3-VL-8B-Instruct | `EmbSpatialBench` | - | 78.50 | 77.70 | -0.80 | ‚úÖ | 77.42 | -1.08 | ‚úÖ |


### 4. MMSI-Bench (no circular)
* **Metric:** Accuracy

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status | EASI (backend=lmms-eval) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct | `MMSIBench_wo_circular` | 26.50 | - | 28.60 | +2.10 | ‚úÖ | 29.30 | +2.80 | ‚òëÔ∏è |
| Qwen2.5-VL-7B-Instruct | `MMSIBench_wo_circular` | 25.90 | - | 26.80 | +0.90 | ‚úÖ | 27.80 | +1.90 | ‚úÖ |
| InternVL3-2B | `MMSIBench_wo_circular` | 25.30 | - | 26.50 | +1.20 | ‚úÖ | 25.90 | +0.60 | ‚úÖ |
| InternVL3-8B | `MMSIBench_wo_circular` | 25.70 | - | 28.00 | +2.30 | ‚úÖ | 26.40 | +0.70 | ‚úÖ |


### 5. VSI-Bench
* **Metric:** Accuracy && MRA

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status | EASI (backend=lmms-eval) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct | `VSI-Bench_128frame` | - | 26.80 | 26.60 | -0.20 | ‚úÖ | 29.59 | +2.79 | ‚òëÔ∏è |
| Qwen2.5-VL-7B-Instruct | `VSI-Bench_128frame` | - | 33.50 | 33.70 | +0.20 | ‚úÖ | 38.67 | +5.17 | ‚ùå |
| InternVL3_5-8B | `VSI-Bench_128frame` | - | 56.30 | 54.20 | -2.10 | ‚úÖ | 54.55 | -1.75 | ‚úÖ |
| Cambrian-S-3B | `VSI-Bench_32frame` | - | 54.73 | 56.08 | +1.35 | ‚úÖ | 54.79 | +0.06 | ‚úÖ |
| Cambrian-S-7B | `VSI-Bench_32frame` | - | 63.61 | 62.93 | -0.68 | ‚úÖ | 63.48 | -0.13 | ‚úÖ |
| SenseNova-SI-1.1-Qwen3-VL-8B | `VSI-Bench_32frame` | 62.90 | - | 62.90 | +0.00 | ‚úÖ | 64.25 | +1.35 | ‚úÖ |
| SenseNova-SI-1.2-InternVL3-8B | `VSI-Bench_32frame` | 68.70 | - | 68.70 | +0.00 | ‚úÖ | 68.35 | -0.35 | ‚úÖ |
| SenseNova-SI-1.1-BAGEL-7B-MoT | `VSI-Bench_32frame` | 41.60 | - | 41.60 | +0.00 | ‚úÖ | 42.53 | +0.93 | ‚úÖ |

*(For the SenseNova-SI-Qwen series models, VSI-Bench should be evaluated using multiple image pathway)*


### 6. VSI-Bench-Debiased
* **Metric:** Accuracy && MRA

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status | EASI (backend=lmms-eval) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct | `VSI-Bench-Debiased_128frame` | 22.70 | - | 22.80 | +0.10 | ‚úÖ | 25.07 | +2.37 | ‚úÖ |
| Qwen2.5-VL-7B-Instruct | `VSI-Bench-Debiased_128frame` | 29.60 | - | 29.10 | -0.50 | ‚úÖ | 33.83 | +4.23 | ‚òëÔ∏è |
| InternVL3_5-8B | `VSI-Bench-Debiased_128frame` | 49.70 | - | 48.40 | -1.30 | ‚úÖ | 49.65 | -0.05 | ‚úÖ |
| Cambrian-S-3B | `VSI-Bench-Debiased_32frame` | - | 46.47 | 48.76 | +2.29 | ‚úÖ | 46.55 | +0.08 | ‚úÖ |
| Cambrian-S-7B | `VSI-Bench-Debiased_32frame` | - | 55.58 | 55.35 | -0.23 | ‚úÖ | 55.40 | -0.18 | ‚úÖ |

### 7. SITE-Bench
* **Metric:** CAA

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status | EASI (backend=lmms-eval) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct | `SiteBenchImage`<br>`SiteBenchVideo_32frame` | 29.50 | - | 33.10 | +3.60 | ‚òëÔ∏è | 29.14 | -0.36 | ‚úÖ |
<!-- | Qwen2.5-VL-7B-Instruct  | `SiteBenchImage`<br>`SiteBenchVideo_32frame` | 31.4 | 32.3 | 37.6 | +5.3 | ‚ùå | -->

### 8. SPAR-Bench
* **Metric:** Accuracy && MRA

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-72B-Instruct  | `SparBench_tiny` | 39.40 | - | 39.84 | +0.44 | ‚úÖ |
| Qwen2.5-VL-7B-Instruct  | `SparBench` | 33.07 | - | 33.78 | +0.71 | ‚úÖ |
| Qwen2.5-VL-72B-Instruct  | `SparBench` | 37.01 | - | 38.94 | +1.93 | ‚úÖ |
| SpaceR-SFT-7B  | `SparBench` | 37.55 | - | 34.12 | -3.43 | ‚òëÔ∏è |


### 9. STARE-Bench
* **Metric:** Accuracy && F1 score

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct  | `StareBench_CoT` | 32.3 | - | 33.7 | +1.4 | ‚úÖ |
| Qwen2.5-VL-7B-Instruct  | `StareBench_CoT` | 36.7 | - | 37.6 | +0.9 | ‚úÖ |


### 10. Spatial-Visualization-Benchmark
* **Metric:** Accuracy

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct  | `SpatialVizBench` | 26.10 | 25.00 | 23.98 | -1.02 | ‚úÖ |
| Qwen2.5-VL-7B-Instruct  | `SpatialVizBench` | 30.76 | - | 31.02 | +0.26 | ‚úÖ |
| InternVL3-8B  | `SpatialVizBench` | 30.25 | - | 31.86 | +1.61 | ‚úÖ |
| Qwen2.5-VL-7B-Instruct  | `SpatialVizBench_CoT` | 27.97 | - | 27.54 | -0.43 | ‚úÖ |
| InternVL3-8B  | `SpatialVizBench_CoT` | 30.08 | - | 30.00 | -0.08 | ‚úÖ |


### 11. OmniSpatial
* **Metric:** Accuracy

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct  | `OmniSpatialBench_manual_cot` | 40.30 | 40.73 | 37.70 | -3.03 | ‚òëÔ∏è |
| Qwen2.5-VL-7B-Instruct  | `OmniSpatialBench_manual_cot` | 40.30 | - | 39.18 | -1.12 | ‚úÖ |
| InternVL3-2B  | `OmniSpatialBench_manual_cot` | 37.98 | - | 42.01 | +4.03 | ‚òëÔ∏è |
| InternVL3-8B  | `OmniSpatialBench_manual_cot` | 41.6 | - | 45.34 | +3.74 | ‚òëÔ∏è |


### 12. ERQA
* **Metric:** Accuracy

| Model | Benchmark | Paper | Qwen3-VL-Report | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen3-VL-8B-Instruct  | `ERQA` | - | 45.8 | 43 | -2.8 | ‚òëÔ∏è |


### 13. RefSpatial-Bench
* **Metric:** 2D coordinates eval

| Model | Benchmark | Paper | Qwen3-VL-Report | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen3-VL-8B-Instruct  | `RefSpatial_wo_unseen` | - | 54.2 | 56.5 | +2.3 | ‚úÖ |


### 14. RoboSpatial-Home
* **Metric:** Accuracy && 2D coordinates eval

| Model | Benchmark | Paper | Qwen3-VL-Report | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen3-VL-8B-Instruct  | `RoboSpatialHome` | - | 66.9 | 62.0 | -4.9 | ‚òëÔ∏è |


### 15. SPBench
* **Metric:** Accuracy && MRA

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-3B-Instruct  | `SPBench-MV` | 36.6 | - | 38.4 | +1.8 | ‚úÖ |
| Qwen2.5-VL-7B-Instruct  | `SPBench-MV` | 37.3 | - | 40.7 | +3.4 | ‚òëÔ∏è |
| Qwen2.5-VL-3B-Instruct  | `SPBench-SI` | 40.3 | - | 41.2 | +0.9 | ‚úÖ |
| Qwen2.5-VL-7B-Instruct  | `SPBench-SI` | 48.4 | - | 48.1 | -0.3 | ‚úÖ |


### 16. MMSI-Video-Bench
* **Metric:** Accuracy

**Main table:**

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-7B-Instruct  | `MMSIVideoBench_50frame` | 29.7 | - | 26.9 | -2.8 | ‚òëÔ∏è |
| Qwen3-VL-8B-Instruct  | `MMSIVideoBench_50frame` | 27.6 | - | 28.3 | +0.7 | ‚úÖ |
| InternVL3-8B  | `MMSIVideoBench_50frame` | 30.4 | - | 30.2 | -0.2 | ‚úÖ |
| InternVL3-78B  | `MMSIVideoBench_50frame` | 32.7 | - | 32.6 | -0.1 | ‚úÖ |
| Gemini-3-pro-preview  | `MMSIVideoBench_50frame` | 38.0 | - | 40.4 | +2.4 | ‚úÖ |

<!-- **Sub bench table:**

| Model | Hard | Med| Easy | **Avg** | &nbsp; | Hard(EASI) | Med(EASI) | Easy(EASI) | **Avg(EASI)** |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | 
| **Qwen2.5-VL-7B** | 11.3 | 29.0 | 46.2 | **29.7** | | 16.2 | 24.8 | 38.3 | **26.9** |
| **Qwen3-VL-8B** | 8.0 | 21.8 | 50.7 | **27.6** | | 11.0 | 25.0 | 46.7 | **28.3** |
| **InternVL3-8B** | 13.8 | 27.5 | 47.8 | **30.4** | | 17.4 | 28.5 | 43.0 | **30.2** |


| Model | IS | Robot | Grd | &nbsp; | IS(EASI) | Robot(EASI) | Grd(EASI) |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **Qwen2.5-VL-7B** | 27.1 | 34.8 | 26.6 | | 25.8 | 27.5 | 30.0 |
| **Qwen3-VL-8B** | 28.7 | 27.0 | 28.7 | | 30.2 | 27.0 | 26.6 |
| **InternVL3-8B** | 27.0 | 37.8 | 31.9 | | 28.9 | 35.3 | 31.0 |

*Note: **IS**: Indoor Scene Perception; **Grd**: Grounding.* -->


### 17. VSI-SUPER-Recall
* **Metric:** Accuracy

| Model | Benchmark | Cambrian-S Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Cambrian-S-7B  | `VsiSuperRecall_10mins_128frame` | 26.7 | - | 26.7 | +0.0 | ‚úÖ |
| Cambrian-S-7B  | `VsiSuperRecall_30mins_128frame` | 21.7 | - | 21.7 | +0.0 | ‚úÖ |
| Cambrian-S-7B  | `VsiSuperRecall_60mins_128frame` | 23.3 | - | 23.3 | +0.0 | ‚úÖ |
| Cambrian-S-7B  | `VsiSuperRecall_120mins_128frame` | 30.0 | - | 30.0 | +0.0 | ‚úÖ |
| Cambrian-S-7B  | `VsiSuperRecall_240mins_128frame` | 28.2 | - | 30.0 | +1.8 | ‚úÖ |


### 18. VSI-SUPER-Count (No streaming)
* **Metric:** Accuracy

| Model | Benchmark | Cambrian-S Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Cambrian-S-7B  | `VsiSuperCount_10mins_128frame` | 16.0 | - | 16.2 | +0.2 | ‚úÖ |
| Cambrian-S-7B  | `VsiSuperCount_30mins_128frame` | 0.0 | - | 0.0 | +0.0 | ‚úÖ |


### 19. STI-Bench
* **Metric:** Accuracy

| Model | Benchmark | Paper | Official Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-72B-Instruct  | `STI-Bench_30frame` | 40.7 | - | 42.1 | +1.4 | ‚úÖ |


### 20. DSR-Bench
* **Metric:** Accuracy

| Model | Benchmark | Paper | Offical Code | EASI (backend=VLMEvalKit) | Œî | Status |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| Qwen2.5-VL-7B-Instruct  | `DSRBench_1fps` | 23.5 | - |24.7 | +1.2 | ‚úÖ |
| Qwen3-VL-8B-Instruct  | `DSRBench_1fps` | 28.7 | - | 30.6 | +1.9 | ‚úÖ |
| InternVL3_5-8B  | `DSRBench_1fps` | 25.4 | - | 26.6 | +1.2 | ‚úÖ |