<div align="center">
  <img src="assets/banner.jpg"/>

  <b>EASI: Holistic Evaluation of Multimodal LLMs on Spatial Intelligence</b>

  [English](README.md) | ç®€ä½“ä¸­æ–‡

</div>

<p align="center">
    <a href="https://arxiv.org/abs/2508.13142" target="_blank">
        <img alt="arXiv" src="https://img.shields.io/badge/arXiv-EASI-red?logo=arxiv" height="20" />
    </a>
    <a href="https://huggingface.co/spaces/lmms-lab-si/EASI-Leaderboard" target="_blank">
        <img alt="Data" src="https://img.shields.io/badge/%F0%9F%A4%97%20_EASI-Leaderboard-ffc107?color=ffc107&logoColor=white" height="20" />
    </a>
    <a href="https://github.com/EvolvingLMMs-Lab/EASI/blob/main/LICENSE"><img src="https://img.shields.io/github/license/EvolvingLMMs-Lab/EASI?style=flat"></a>
</p>

## å¿«é€Ÿäº†è§£ï¼ˆTL;DRï¼‰

- EASI æ˜¯ä¸€ä¸ªé¢å‘å¤šæ¨¡æ€å¤§æ¨¡å‹ç©ºé—´æ™ºèƒ½ï¼ˆSpatial Intelligenceï¼‰çš„ç»Ÿä¸€è¯„æµ‹å¥—ä»¶ã€‚
- EASI æ”¯æŒ**ä¸¤ç§è¯„æµ‹åç«¯**ï¼š[VLMEvalKit](https://github.com/open-compass/VLMEvalKit) å’Œ [lmms-eval](https://github.com/EvolvingLMMs-Lab/lmms-eval)ã€‚
- å®Œæˆå®‰è£…åï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„å‘½ä»¤å¿«é€Ÿè·‘ä¸€ä¸ªç¤ºä¾‹ï¼š

**ä½¿ç”¨ EASI (VLMEvalkit åç«¯)ï¼š**
```bash
cd VLMEvalKit/
python run.py --data MindCubeBench_tiny_raw_qa \
              --model SenseNova-SI-1.3-InternVL3-8B \
              --verbose --reuse --judge extract_matching
```

**ä½¿ç”¨ EASI (LMMs-Eval åç«¯)ï¼š**
```bash
lmms-eval --model qwen2_5_vl \
          --model_args pretrained=sensenova/SenseNova-SI-1.1-Qwen2.5-VL-3B \
          --tasks site_bench_image \
          --batch_size 1 \
          --log_samples \
          --output_path ./logs/
```

## æ¦‚è¿°

EASI æ˜¯ä¸€ä¸ªé¢å‘ç©ºé—´æ™ºèƒ½çš„ç»Ÿä¸€è¯„æµ‹å¥—ä»¶ï¼Œç”¨äºåœ¨ä¸æ–­æ‰©å±•çš„ç©ºé—´åŸºå‡†ä¸Šè¯„ä¼°æœ€å…ˆè¿›çš„é—­æºå’Œå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚

- **å¹¿æ³›æ”¯æŒ**ï¼šç›®å‰ EASI([v0.2.0](https://github.com/EvolvingLMMs-Lab/EASI/releases/tag/0.2.0))æ”¯æŒ **23 ä¸ªç©ºé—´æ™ºèƒ½æ¨¡å‹**å’Œ **25 ä¸ªç©ºé—´åŸºå‡†æµ‹è¯•**ã€‚
- **åŒåç«¯æ”¯æŒ**ï¼š
  - **VLMEvalKit**ï¼šä¸°å¯Œçš„æ¨¡å‹åº“ï¼Œå†…ç½®è¯„åˆ¤åŠŸèƒ½ã€‚
  - **lmms-eval**ï¼šè½»é‡çº§ã€åŸºäº accelerate çš„åˆ†å¸ƒå¼è¯„æµ‹ï¼Œæ”¯æŒå¤§é‡ä»»åŠ¡ã€‚

æ›´å¤šè¯¦æƒ…è¯·å‚é˜… ğŸ‘‰ **[Supported Models & Benchmarks](docs/Support_bench_models.md)**ã€‚EASI åŒæ—¶æä¾›é€æ˜çš„ ğŸ‘‰ **[Benchmark Verification](docs/Benchmark_Verification.md)** ä»¥ä¾›ä¸å®˜æ–¹åˆ†æ•°å¯¹æ¯”ã€‚

## ğŸ—“ï¸ æœ€æ–°åŠ¨æ€

ğŸŒŸ **[2026-01-16]** [EASI v0.2.0](https://github.com/EvolvingLMMs-Lab/EASI/releases/tag/0.2.0) å‘å¸ƒã€‚ä¸»è¦æ›´æ–°åŒ…æ‹¬ï¼š
- **æ–°å¢åç«¯æ”¯æŒ**ï¼šé›†æˆäº† lmms-eval ä¸ VLMEvalKitï¼Œæä¾›çµæ´»çš„è¯„æµ‹é€‰æ‹©ã€‚
- **åŸºå‡†æ”¯æŒæ‰©å±•**ï¼šæ–°å¢ DSR-Benchã€‚

å®Œæ•´å‘ç‰ˆå†å²å’Œè¯¦ç»†æ›´æ–°æ—¥å¿—ï¼Œè¯·å‚è§ ğŸ‘‰ **[Changelog](docs/CHANGELOG.md)**ã€‚

## ğŸ› ï¸ å¿«é€Ÿä¸Šæ‰‹
### å®‰è£…

EASI æä¾›ä¸¤ç§è¯„æµ‹åç«¯ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦å®‰è£…å…¶ä¸­ä¸€ä¸ªæˆ–ä¸¤ä¸ªã€‚

#### æ–¹å¼ä¸€ï¼šæœ¬åœ°ç¯å¢ƒï¼ˆVLMEvalKit åç«¯ï¼‰

```bash
git clone --recursive https://github.com/EvolvingLMMs-Lab/EASI.git
cd EASI
pip install -e ./VLMEvalKit
```

#### æ–¹å¼äºŒï¼šæœ¬åœ°ç¯å¢ƒï¼ˆlmms-eval åç«¯ï¼‰

```bash
git clone --recursive https://github.com/EvolvingLMMs-Lab/EASI.git
cd EASI
pip install -e ./lmms-eval spacy
# æ¨èä¾èµ–
# åœ¨ pyproject.toml ä¸­ä½¿ç”¨ "torch==2.7.1", "torchvision==0.22.1"ï¼ˆé€‚ç”¨äºå¤§å¤šæ•°æ¨¡å‹ï¼‰
# å®‰è£… flash-attn ä»¥åŠ é€Ÿæ¨ç†
pip install flash-attn --no-build-isolation
```

#### æ–¹å¼ä¸‰ï¼šåŸºäºDocker

```bash
bash dockerfiles/EASI/build_runtime_docker.sh

docker run --gpus all -it --rm \
  -v /path/to/your/data:/mnt/data \
  --name easi-runtime \
  vlmevalkit_EASI:latest \
  /bin/bash
```

### è¯„æµ‹

EASI æ”¯æŒä¸¤ç§è¯„æµ‹åç«¯ï¼Œè¯·æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„åç«¯ã€‚

---

#### åç«¯ 1ï¼šVLMEvalKit

**é€šç”¨å‘½ä»¤**
```bash
python run.py --data {BENCHMARK_NAME} --model {MODEL_NAME} --judge {JUDGE_MODE} --verbose --reuse
```
è¯·å‚é˜…ä¸‹æ–¹çš„"é…ç½®"éƒ¨åˆ†ï¼ŒæŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•çš„å®Œæ•´åˆ—è¡¨ã€‚è¯·å‚é˜… `run.py` æ–‡ä»¶ï¼ŒæŸ¥çœ‹æ‰€æœ‰å‚æ•°çš„å®Œæ•´åˆ—è¡¨ã€‚

**ç¤ºä¾‹**

åœ¨ `MindCubeBench_tiny_raw_qa` ä¸Šè¯„æµ‹ `SenseNova-SI-1.3-InternVL3-8B`ï¼š

```bash
python run.py --data MindCubeBench_tiny_raw_qa \
              --model SenseNova-SI-1.3-InternVL3-8B \
              --verbose --reuse --judge extract_matching
```
è¿™å°†ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥æå–ç­”æ¡ˆã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨åŸºäº LLM çš„è¯„åˆ¤ç³»ç»Ÿï¼ˆä¾‹å¦‚ï¼Œåœ¨è¯„ä¼° SpatialVizBench_CoT æ—¶ï¼‰ï¼Œæ‚¨å¯ä»¥å°†è¯„åˆ¤ç³»ç»Ÿåˆ‡æ¢åˆ° OpenAIï¼š
```bash
export OPENAI_API_KEY=YOUR_KEY
python run.py --data SpatialVizBench_CoT \
              --model {MODEL_NAME} \
              --verbose --reuse --judge gpt-4o-1120
```

---

#### åç«¯ 2ï¼šlmms-eval

lmms-eval æä¾›åŸºäº accelerate çš„åˆ†å¸ƒå¼è¯„æµ‹ï¼Œæ”¯æŒå¤š GPU æ¨ç†ã€‚

**é€šç”¨å‘½ä»¤**
```bash
lmms-eval --model {MODEL_TYPE} \
          --model_args pretrained={MODEL_PATH} \
          --tasks {TASK_NAME} \
          --batch_size 1 \
          --log_samples \
          --output_path ./logs/
```

**ç¤ºä¾‹ï¼šå• GPU**

åœ¨ `site_bench_image` ä¸Šè¯„æµ‹ `Qwen2.5-VL-3B-Instruct`ï¼š

```bash
lmms-eval --model qwen2_5_vl \
          --model_args pretrained=Qwen/Qwen2.5-VL-3B-Instruct \
          --tasks site_bench_image \
          --batch_size 1 \
          --log_samples \
          --output_path ./logs/
```

**ç¤ºä¾‹ï¼šå¤š GPUï¼ˆä½¿ç”¨ accelerateï¼‰**

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch \
    --num_processes=4 \
    --num_machines=1 \
    --mixed_precision=no \
    --dynamo_backend=no \
    --main_process_port=12346 \
    -m lmms_eval \
    --model qwen2_5_vl \
    --model_args pretrained=Qwen/Qwen2.5-VL-3B-Instruct,attn_implementation=flash_attention_2 \
    --tasks site_bench_image \
    --batch_size 1 \
    --log_samples \
    --output_path ./logs/
```

**åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡**
```bash
lmms-eval --tasks list
```

æ›´å¤š lmms-eval ä½¿ç”¨è¯¦æƒ…ï¼Œè¯·å‚é˜… [lmms-eval/docs/](lmms-eval/docs/) ä¸­çš„æ–‡æ¡£ï¼ŒåŒ…æ‹¬ [æ¨¡å‹æŒ‡å—](lmms-eval/docs/model_guide.md)ã€[ä»»åŠ¡æŒ‡å—](lmms-eval/docs/task_guide.md) å’Œ [è¿è¡Œç¤ºä¾‹](lmms-eval/docs/run_examples.md)ã€‚

---

### é…ç½®

**EASI (åç«¯=VLMEvalKit)**
- **æ¨¡å‹**ï¼šå®šä¹‰åœ¨ `vlmeval/config.py` ä¸­ã€‚è¯·ä½¿ç”¨ `vlmutil check {MODEL_NAME}` éªŒè¯æ¨ç†æ˜¯å¦å¯ç”¨ã€‚
- **åŸºå‡†**ï¼šå®Œæ•´æ”¯æŒåˆ—è¡¨è¯·è§ [VLMEvalKit Supported Benchmarks](https://aicarrier.feishu.cn/wiki/Qp7wwSzQ9iK1Y6kNUJVcr6zTnPe?table=tblsdEpLieDoCxtb&view=vewa8sGZrY)ã€‚
- **EASI ç‰¹æœ‰**ï¼šé’ˆå¯¹ [EASI Leaderboard](https://huggingface.co/spaces/lmms-lab-si/easi-leaderboard)ï¼Œç›¸å…³åŸºå‡†æµ‹è¯•æ±‡æ€»äº [æ”¯æŒçš„æ¨¡å‹ä¸åŸºå‡†](docs/Support_bench_models.md)ã€‚

**EASI (åç«¯=lmms-eval)**
- **æ¨¡å‹**ï¼šlmms-eval æ”¯æŒå¤šç§æ¨¡å‹ç±»å‹ï¼ˆå¦‚ `qwen2_5_vl`, `llava`, `internvl2` ç­‰ï¼‰ã€‚ä½¿ç”¨ `--model_args` æŒ‡å®šæ¨¡å‹å‚æ•°ï¼ˆå¦‚ `pretrained`, `attn_implementation` ç­‰ï¼‰ã€‚
- **ä»»åŠ¡**ï¼šä»»åŠ¡å®šä¹‰åœ¨ `lmms-eval/lmms_eval/tasks/`ã€‚åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡ï¼š
  ```bash
  lmms-eval --tasks list
  ```

  ç©ºé—´æ™ºèƒ½è¯„æµ‹çš„ç¤ºä¾‹ä»»åŠ¡ï¼š
  | ä»»åŠ¡åç§° | æè¿° |
  |-----------|-------------|
  | `site_bench_image` | SITE-Bench å›¾åƒè¯„æµ‹ |
  | `site_bench_video` | SITE-Bench è§†é¢‘è¯„æµ‹ |

  æ›´å¤š lmms-eval ä½¿ç”¨è¯¦æƒ…ï¼Œè¯·å‚é˜… [lmms-eval æ–‡æ¡£](lmms-eval/README.md)ã€‚

### æäº¤

å°†æ‚¨çš„è¯„æµ‹ç»“æœæäº¤åˆ°æˆ‘ä»¬çš„ [EASI Leaderboard](https://huggingface.co/spaces/lmms-lab-si/easi-leaderboard)ï¼š

1. è®¿é—® [EASI Leaderboard](https://huggingface.co/spaces/lmms-lab-si/easi-leaderboard) é¡µé¢ã€‚
2. ç‚¹å‡» **ğŸš€ Submit here!** è¿›å…¥æäº¤è¡¨å•ã€‚
3. æŒ‰ç…§é¡µé¢ä¸Šçš„è¯´æ˜å¡«å†™æäº¤è¡¨å•ï¼Œå¹¶æäº¤ä½ çš„ç»“æœã€‚

## ğŸ–Šï¸ å¼•ç”¨

```bib
@article{easi2025,
  title={Holistic Evaluation of Multimodal LLMs on Spatial Intelligence},
  author={Cai, Zhongang and Wang, Yubo and Sun, Qingping and Wang, Ruisi and Gu, Chenyang and Yin, Wanqi and Lin, Zhiqian and Yang, Zhitao and Wei, Chen and Shi, Xuanke and Deng, Kewang and Han, Xiaoyang and Chen, Zukai and Li, Jiaqi and Fan, Xiangyu and Deng, Hanming and Lu, Lewei and Li, Bo and Liu, Ziwei and Wang, Quan and Lin, Dahua and Yang, Lei},
  journal={arXiv preprint arXiv:2508.13142},
  year={2025}
}
```
